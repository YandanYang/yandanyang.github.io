<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yandan Yang</title>

    <meta name="author" content="Yandan Yang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                    <name style="font-size: 36px; font-weight: bold; display: block;">Yandan Yang</name> 
                    <!-- <br> -->
                    <!-- yangyandan96[at]gmail.com  -->
                  </p>
		I'm a research engineer at <a href="https://www.bigai.ai/">BIGAI</a> in Beijing, China.  

        My interests lie in computer vision and artificial intelligence, with a special focus on scene synthesis and generative AI.
        
        I used to work as an algorithm engineer in <a href="https://www.tencent.com/en-us/">Tencent</a> in 2021-2023.

        Previously, I received my Master (2021) & Bachelor(2018) degree from Beihang University, in China. 

                </p>
                <p style="text-align:center">
                  <a href="mailto:yangyandan96@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="???">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=H6OwSzsAAAAJ&hl=zh-CN">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/yandan_yan32100">Twitter</a> &nbsp;/&nbsp;
                  <!-- <a href="https://bsky.app/profile/jonbarron.bsky.social">Bluesky</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/YandanYang/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.xiaohongshu.com/user/profile/596cdabf5e87e77f571bfc3e?exSource=">rednote 小红书</a> 
                  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0&icon_names=heart_check" />
                  <span class="material-symbols-outlined" style="color: rgb(255, 88, 88);">
                    heart_check
                    </span>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/YandanYang.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/YandanYang.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <!-- <p> -->
                  <!-- I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>. -->
                <!-- </p> -->
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    

    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="col-md-4" align="center"> 
              <img src="images/metascenes.gif" class="thumbnail img-responsive" style="max-height:80px;">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <!-- <a > -->
            <h4 class="papertitle">MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans
              </h4>
          <!-- </a> -->
          <!-- <br> -->
          
          <a>Huangyue Yu*</a>,
          <a href="https://buzz-beater.github.io/">Baoxiong Jia*</a>,
          <a href="https://yixchen.github.io">Yixin Chen*</a>,
          <strong>Yandan Yang</strong>,
          <a href="https://xiaoyao-li.github.io/">Puhao Li</a>,
          <a href="https://scholar.google.com/citations?user=rY-Ndl0AAAAJ">Rongpeng Su</a>,
          <a href="https://gauleejx.github.io/">Jiaxin Li</a>,
          <a href="https://liqing-ustc.github.io/">Qing Li</a>,
          <a href="https://liangwei-bit.github.io/web/">Wei Liang</a>,
          <a href="https://zhusongchun.net/">Song-Chun Zhu</a>,
          <a href="https://tengyu.ai/">Tengyu Liu</a>,
          <a href="https://siyuanhuang.com/">Siyuan Huang</a>,
          
          
          <div class="pubcite"> 
              <i>
                  <font size="3">Conference on Computer Vision and Pattern Recognition (CVPR) 2025</font>
              </i>
              <!-- <i> -->
                  <!-- <font size="3">(<strong><font color="red">Highlight</font></strong>)</font> -->
              <!-- </i>  -->
              <br> AI3DG @ CVPR 2025 (* indicates equal contribution.) <br> 
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/CVPR2025-Conference%20Paper-green.svg">
              </label> 
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/Digital%20Twin%20Creation-blue.svg">
              </label>
          </div> 
  
          
          <a href="paper/metascenes.pdf">Paper</a>
          /
          <a href="https://meta-scenes.github.io/">Project</a>
          <!-- / -->
          <!-- <a>Code</a> -->
          <p></p>
          <p>
          <!-- We introduce PhyScene, a novel method dedicated to generating interactive 3D scenes characterized by realistic layouts, articulated objects, and rich physical interactivity tailored for embodied agents.. -->
          </p>
        </td>
      </tr>
  

      <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="col-md-4" align="center"> 
              <img src="images/physcene.gif" class="thumbnail img-responsive" style="max-height:160px;">
          </div>
          <!-- <script type="text/javascript">
            function bolt3d_start() {
              document.getElementById('bolt3d_image').style.opacity = "1";
            }
  
            function bolt3d_stop() {
              document.getElementById('bolt3d_image').style.opacity = "0";
            }
            bolt3d_stop()
          </script> -->
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <!-- <a> -->
            <h4 class="papertitle">PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI
              </h4>
          <!-- </a> -->
          <!-- <br> -->
          
          <strong>Yandan Yang*</strong>,
          <a href="https://buzz-beater.github.io/">Baoxiong Jia*</a>,
          <a>Peiyuan Zhi</a>,
          <a href="https://siyuanhuang.com/">Siyuan Huang</a>,
  
          
          <div class="pubcite"> 
              <i>
                  <font size="3">Conference on Computer Vision and Pattern Recognition (CVPR) 2024</font>
              </i>
              <i>
                  <font size="3">(<strong><font color="red">Highlight</font></strong>)</font>
              </i> 
              <br> AI3DG @ CVPR 2024 (* indicates equal contribution.) <br> 
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/CVPR2024-Conference%20Paper-green.svg">
              </label> 
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/Physics--Guided%20Scene%20Synthesis-blue.svg">
              </label>
          </div> 
  
          
          <a href="paper/physcene.pdf">Paper</a>
          /
          <a href="https://physcene.github.io/">Project</a>
          /
          <a href="https://github.com/PhyScene/PhyScene/tree/main">Code</a>
          <p></p>
          <p>
          We introduce PhyScene, a novel method dedicated to generating interactive 3D scenes characterized by realistic layouts, articulated objects, and rich physical interactivity tailored for embodied agents..
          </p>
        </td>
      </tr>
      


      <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="col-md-4" align="center"> 
              <img src="images/LDG.png" class="thumbnail img-responsive" style="max-height:160px;">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <!-- <a> -->
            <h4 class="papertitle">Latent Domain Generation for Unsupervised
              Domain Adaptation Object Counting
              </h4>
          <!-- </a> -->
          <!-- <br> -->

          <a href="https://scholar.google.com/citations?user=sgQ0XVgAAAAJ&hl=zh-CN/">Anran Zhang</a>,
          <strong>Yandan Yang</strong>,
          <a href="https://csjunxu.github.io/">Jun Xu</a>,
          <a>Xianbin Cao</a>,
          <a href="https://scholar.google.ca/citations?user=DnBb3e0AAAAJ&hl=en"> Xiantong Zhen</a>,
          <a href="https://ling-shao.github.io/"> Ling Shao</a>,
          
          
          <div class="pubcite"> 
              <i>
                  <font size="3">IEEE TRANSACTIONS ON MULTIMEDIA(TMM) 2023</font>
              </i>
              <br>
              <!-- <i>
                  <font size="3">(<strong><font color="red">Highlight</font></strong>)</font>
              </i>  -->
              <!-- <br> AI3DG @ CVPR 2025 (* indicates equal contribution.) <br>  -->
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/TMM 2023-Journal%20Paper-yellow.svg">
              </label> 
              <!-- <label class="pubtype">
                  <img src="https://img.shields.io/badge/Digital%20Twin%20Creation-blue.svg">
              </label> -->
          </div> 
  
          
          <a href="paper/LDG.pdf">Paper</a>
          <!-- / -->
          <!-- <a href="https://meta-scenes.github.io/">Project</a> -->
          <!-- / -->
          <!-- <a>Code</a> -->
          <p></p>
          <p>
          <!-- We introduce PhyScene, a novel method dedicated to generating interactive 3D scenes characterized by realistic layouts, articulated objects, and rich physical interactivity tailored for embodied agents.. -->
          </p>
        </td>
      </tr>


      
      <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="col-md-4" align="center"> 
              <img src="images/IncreACO.png" class="thumbnail img-responsive" style="max-height:150px;">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <!-- <a> -->
            <h4 class="papertitle">IncreACO: Incrementally Learned Automatic Check-out with Photorealistic
              Exemplar Augmentation
              </h4>
          <!-- </a> -->
          <!-- <br> -->
          
          <strong>Yandan Yang</strong>,
          <a href="https://lucassheng.github.io/">Lu Sheng</a>,
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=G0Ow8j8AAAAJ">Xiaolong Jiang</a>,
          <a href="https://huyutao0910.github.io/">Haochen Wang</a>,
          <a href="https://www.cs.hku.hk/people/academic-staff/dongxu">Dong Xu</a>,
          <a>Xianbin Cao</a>,
          
          <div class="pubcite"> 
              <i>
                  <font size="3">WACV 2021</font>
              </i>
              <br>
              <!-- <i>
                  <font size="3">(<strong><font color="red">Highlight</font></strong>)</font>
              </i>  -->
              <!-- <br> AI3DG @ CVPR 2025 (* indicates equal contribution.) <br>  -->
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/WACV 2021-Conference%20Paper-green.svg">
              </label> 
              <!-- <label class="pubtype">
                  <img src="https://img.shields.io/badge/Digital%20Twin%20Creation-blue.svg">
              </label> -->
          </div> 
  
          
          <a href="paper/IncreACO.pdf">Paper</a>
          <!-- / -->
          <!-- <a href="https://meta-scenes.github.io/">Project</a> -->
          <!-- / -->
          <!-- <a>Code</a> -->
          <p></p>
          <p>
          <!-- We introduce PhyScene, a novel method dedicated to generating interactive 3D scenes characterized by realistic layouts, articulated objects, and rich physical interactivity tailored for embodied agents.. -->
          </p>
        </td>
      </tr>



      <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="col-md-4" align="center"> 
              <img src="images/AKEN.png" class="thumbnail img-responsive" style="max-height:140px;">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <!-- <a> -->
            <h4 class="papertitle">Attentional Kernel Encoding Networks for Fine-Grained Visual Categorization
              </h4>
          <!-- </a> -->
          <!-- <br> -->

          <a href="https://huyutao0910.github.io/">Yutao Hu</a>,
          <strong>Yandan Yang</strong>,
          <a>Jun Zhang</a>,
          <a>Xianbin Cao</a>,
          <a href="https://scholar.google.ca/citations?user=DnBb3e0AAAAJ&hl=en"> Xiantong Zhen</a>,
          
          
          <div class="pubcite"> 
              <i>
                  <font size="3">IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY(​IEEE TCSVT​) 2021</font>
              </i>
              <br>
              <!-- <i>
                  <font size="3">(<strong><font color="red">Highlight</font></strong>)</font>
              </i>  -->
              <!-- <br> AI3DG @ CVPR 2025 (* indicates equal contribution.) <br>  -->
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/TCSVT 2021-Journal%20Paper-yellow.svg">
              </label> 
              <!-- <label class="pubtype">
                  <img src="https://img.shields.io/badge/Digital%20Twin%20Creation-blue.svg">
              </label> -->
          </div> 
  
          
          <a href="paper/AKEN.pdf">Paper</a>
          <!-- / -->
          <!-- <a href="https://meta-scenes.github.io/">Project</a> -->
          <!-- / -->
          <!-- <a>Code</a> -->
          <p></p>
          <p>
          <!-- We introduce PhyScene, a novel method dedicated to generating interactive 3D scenes characterized by realistic layouts, articulated objects, and rich physical interactivity tailored for embodied agents.. -->
          </p>
        </td>
      </tr>
      


      <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  >
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="col-md-4" align="center"> 
              <img src="images/DAN.png" class="thumbnail img-responsive" style="max-height:200px;">
          </div>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <!-- <a> -->
            <h4 class="papertitle">Few-shot semantic segmentation with democratic attention networks
              </h4>
          <!-- </a> -->
          <!-- <br> -->
          
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=WTZX3y8AAAAJ">Haochen Wang*</a>,
          <a>Xudong Zhang*</a>,
          <a href="https://huyutao0910.github.io/">Yutao Hu</a>,
          <strong>Yandan Yang</strong>,
          <a>Xianbin Cao</a>,
          <a href="https://scholar.google.ca/citations?user=DnBb3e0AAAAJ&hl=en"> Xiantong Zhen</a>,
          
          
          <div class="pubcite"> 
              <i>
                  <font size="3">ECCV 2020</font>
              </i>
              <br>
              <!-- <i>
                  <font size="3">(<strong><font color="red">Highlight</font></strong>)</font>
              </i>  -->
              <!-- <br> AI3DG @ CVPR 2025 (* indicates equal contribution.) <br>  -->
              <label class="pubtype">
                  <img src="https://img.shields.io/badge/ECCV 2020-Conference%20Paper-green.svg">
              </label> 
              <!-- <label class="pubtype">
                  <img src="https://img.shields.io/badge/Digital%20Twin%20Creation-blue.svg">
              </label> -->
          </div> 
  
          
          <a href="paper/DAN.pdf">Paper</a>
          <!-- / -->
          <!-- <a href="https://meta-scenes.github.io/">Project</a> -->
          <!-- / -->
          <!-- <a>Code</a> -->
          <p></p>
          <p>
          <!-- We introduce PhyScene, a novel method dedicated to generating interactive 3D scenes characterized by realistic layouts, articulated objects, and rich physical interactivity tailored for embodied agents.. -->
          </p>
        </td>
      </tr>


    </table>
  
    <p align="right">
        <font size="2">
        <a href="https://jonbarron.info/">The style of this website is borrowed from this webpage.</a>
        </font>
    </p>
</body>
</html>